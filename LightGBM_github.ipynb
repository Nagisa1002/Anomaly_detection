{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LightGBM_github.ipynb ",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nagisa1002/Anomaly_detection/blob/main/LightGBM_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4vcbiuTrARS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545d6071-7271-4cbd-d91b-5e611e1b82c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crw6XJ5pYba_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY_9jM6IrWJw"
      },
      "source": [
        "from datetime import datetime \n",
        "import os \n",
        "import sys\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from keras.utils import np_utils\n",
        "\n",
        "##data preprocessing##\n",
        "'''\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "#over/under sampling\n",
        "!pip install imbalanced-learn\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "'''\n",
        "\n",
        "##model##\n",
        "'''\n",
        "import lightgbm as lgb\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from catboost import Pool\n",
        "'''\n",
        "\n",
        "##parameter　turning##\n",
        "'''\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#lgb用\n",
        "! pip install optuna\n",
        "import optuna.integration.lightgbm as lgb\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwIYFB-10rLq"
      },
      "source": [
        "#parameters\n",
        "test_size=0.1\n",
        "model_type='LightGBM'\n",
        "\n",
        "sampling_type=0  #0:None, 1:undersampling, 2:oversampling\n",
        "processing_type=3 #0:None, 1:StandardScaler, 2:MinMaxScaler, 3: RobustScaler\n",
        "\n",
        "#path\n",
        "EXEC_TIME = datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
        "LOG_DIR = f'/content/drive/MyDrive/{EXEC_TIME}' \n",
        "RESULT_DIR =  f'{LOG_DIR}/score.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnl2uhqMqeZ3"
      },
      "source": [
        "def data_sampling(X_train:np.array, y_train:np.array):\n",
        "    if sampling_type==1:\n",
        "      sampling = RandomUnderSampler(random_state=100)\n",
        "    else:\n",
        "      sampling = SMOTE()\n",
        "\n",
        "    X_train, y_train = sampling.fit_sample(X_train, y_train)\n",
        "    return X_train, y_train\n",
        "    \n",
        "def preprocessing(X_train, X_test, type:str):\n",
        "  if processing_type==1: \n",
        "    sc = StandardScaler()\n",
        "  elif processing_type==2:\n",
        "    sc = MinMaxScaler(feature_range=(-1, 1), copy=True)\n",
        "  else:\n",
        "    sc = RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0), copy=True) \n",
        "\n",
        "  X_train = sc.fit_transform(X_train)\n",
        "  X_test = sc.transform(X_test)\n",
        "  return X_train, X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XapzIW4vretx"
      },
      "source": [
        "def load_data(path:str):\n",
        "  '''\n",
        "  load data and divide the data into Objective Variable and Explanatory Variable.\n",
        "  Assumption1 : Objective Variable(label/y_true) is in the column 'y_true'  in the data\n",
        "  Assumption2: data file is csv\n",
        "  '''\n",
        "\n",
        "  df = pd.read_csv(path, index_col=0)\n",
        "  print('all_data:',df.shape, end='')\n",
        "\n",
        "  label = list(set(df['y_true'].values))\n",
        "  num_classes=len(label)\n",
        "\n",
        "  y = {}\n",
        "  X = {}\n",
        "  for i, fc in enumerate(label):\n",
        "    data = df[df['y_true'] == label]\n",
        "    X[label] = data.drop(DEL_LABEL, axis=1).values\n",
        "    y[label] = np.full(X[fc].shape[0], i)\n",
        "  \n",
        "  X_data = np.vstack([X[fc] for fc in FC])\n",
        "  y_data = np.hstack([y[fc] for fc in FC])\n",
        "  print(f' -> X:{X_data.shape}, y:{y_data.shape}')\n",
        "  return X_data, y_data\n",
        "\n",
        "def get_data():\n",
        "  '''\n",
        "  Select the location of the training and test data file, and load data.\n",
        "  And split the train data into train data and test data\n",
        "  (+perform preprocessing and sampling)\n",
        "  '''\n",
        "  X_train, y_train, num_classes = load_data(train_path='')\n",
        "  X_test, y_test, num_classes = load_data(test_path='')\n",
        "\n",
        "  if sampling_type!='None':\n",
        "    X_train, y_train = data_sampling(X_train, y_train)\n",
        "  \n",
        "  if prosessing_type!='None':\n",
        "    X_train, X_test=preprocessing(X_train, X_test)\n",
        "\n",
        "  X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=test_size, random_state=0, shuffle=True, stratify=y_train)\n",
        "\n",
        "  if model_type='CatBoost':\n",
        "    X_tr = Pool(X_tr, label=y_tr)  \n",
        "    X_val = Pool(X_val, label=y_val)  \n",
        "    X_test = Pool(X_test, label=y_test)\n",
        "\n",
        "  return X_tr, y_tr, X_val, y_val, X_test, y_test, num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F75eTSc28B8G"
      },
      "source": [
        "def plot_cm(y, y_pred, num_classes):\n",
        "  '''\n",
        "  plot confusion matrix\n",
        "  '''\n",
        "  fig = plt.figure(figsize=(num_classes*10,num_classes*10))\n",
        "  fig, ax = plt.subplots(figsize=(num_classes, num_classes))\n",
        "  confmat=confusion_matrix(y, y_pred)\n",
        "  ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3) \n",
        "\n",
        "  for i in range(confmat.shape[0]):\n",
        "      for j in range(confmat.shape[1]):\n",
        "          ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "  plt.xticks(np.arange(0, num_classes, 1)) \n",
        "  plt.yticks(np.arange(0, num_classes, 1))  \n",
        "  plt.title('Predicted Label')\n",
        "  plt.ylabel('True Label')\n",
        "  fig.savefig(f'{LOG_DIR}/cm.png')\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W01pfesvccE-"
      },
      "source": [
        "def plot_history(evaluation_results):\n",
        "  '''\n",
        "  plot learning curve\n",
        "  '''\n",
        "  fig = plt.figure()\n",
        "  ax = plt.subplot()\n",
        "  ax.plot(evaluation_results['train']['multi_logloss'], label='train')\n",
        "  ax.plot(evaluation_results['valid']['multi_logloss'], label='valid')\n",
        "  plt.ylabel('Log loss')\n",
        "  plt.xlabel('Boosting round')\n",
        "  plt.title('Training performance')\n",
        "  plt.legend()\n",
        "  fig.savefig(f'{LOG_DIR}/history.png')\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnUlsWH7Z7ti"
      },
      "source": [
        "def train_model(X_tr:np.array, y_tr:np.array, X_val:np.array, y_val:np.array, num_classes, f):\n",
        "  '''\n",
        "  Choice model and training\n",
        "  '''\n",
        "  if model_type=='SVC':\n",
        "    model = SVC(kernel='rbf')\n",
        "\n",
        "  elif model_type=='RF':\n",
        "    model = RandomForestClassifier(random_state=0)\n",
        "    \n",
        "  elif model_type=='LR': \n",
        "     model=LogisticRegressionCV(cv=10, random_state=0)\n",
        "    \n",
        "    \n",
        "  elif model_type=='CatBoost':\n",
        "    model = CatBoostClassifier(custom_loss=['Accuracy'], random_seed=0)\n",
        "    model.fit(X_tr, \n",
        "          eval_set=X_val,    \n",
        "          early_stopping_rounds=20,\n",
        "          use_best_model=True, \n",
        "          plot=True)\n",
        "\n",
        "  elif model_type=='LightGBM':\n",
        "    evaluation_results = {} \n",
        "    best_params = {}\n",
        "\n",
        "    lgb_tr = lgb.Dataset(X_tr, label = y_tr)\n",
        "    lgb_val = lgb.Dataset(X_val, label = y_val, reference=lgb_tr)\n",
        "\n",
        "    params = {\n",
        "          'objective': 'multiclass', \n",
        "          'num_class': num_classes, \n",
        "    }\n",
        "\n",
        "    model = lgb.train(\n",
        "                    params,\n",
        "                    train_set=lgb_tr, \n",
        "                    evals_result=evaluation_results,\n",
        "                    valid_sets=[lgb_tr, lgb_val],\n",
        "                    valid_names=['train', 'valid'],\n",
        "                    early_stopping_rounds=15,\n",
        "                    num_boost_round=100,\n",
        "                    )\n",
        "    plot_history(evaluation_results)\n",
        "    #print(model.params,file=f)\n",
        "\n",
        "  else:\n",
        "    sys.exit('Plese input correct model_type.')\n",
        "    \n",
        "  if model_type!='CatBoost' and model_type!='LightGBM':  \n",
        "    model.fit(X_tr, y_tr)\n",
        "    #gscv = GridSearchCV(model, param_grid=params, scoring='f1_macro', verbose=1)\n",
        "    #print(gscv.best_params_, gscv.best_score_)\n",
        "\n",
        "  filepath = f'{LOG_DIR}/model.learn'\n",
        "  joblib.dump(model, filepath)\n",
        "  model = joblib.load(filepath)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnLz3wgZMFYA"
      },
      "source": [
        "def predict_model(model, X:np.array, f):      \n",
        "  if model_type='LightGBM':\n",
        "    y_pred = model.predict(X, num_iteration=model.best_iteration)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "  else:\n",
        "    y_pred = model.predict(X)\n",
        "  return y_pred\n",
        "\n",
        "def get_score(y, y_pred):\n",
        "  acc= accuracy_score(y, y_pred)\n",
        "  micro_f1= f1_score(y, y_pred,average='micro')\n",
        "  macro_f1= f1_score(y, y_pred, average='macro')\n",
        "  weighted_f1= f1_score(y, y_pred, average='weighted')\n",
        "  class_f1= f1_score(y, y_pred, average=None)\n",
        "  class_precision=precision_score(y, y_pred, average=None)\n",
        "  class_recal=recall_score(y, y_pred, average=None)\n",
        "\n",
        "  print(f'--- SCORE---',file=f)\n",
        "  print('accuracy', acc , file=f)\n",
        "  print('macro_f1', macro_f1, file=f)\n",
        "  print('weighted_f1', weighted_f1, file=f)\n",
        "  print('class_f1', weighted_f1, file=f)\n",
        "  print('class_precision', class_precision, file=f)\n",
        "  print('class_recall', class_recal, file=f)\n",
        "  print(file=f)\n",
        "\n",
        "  plot_cm(y, y_pred, num_classes) \n",
        "  return "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpAlAMkXr799"
      },
      "source": [
        "def train(X_tr, y_tr, X_val, y_val, X_test, y_test, num_classes):\n",
        "    with open(RESULT_DIR, mode='w') as f:\n",
        "      print(model_type, file=f)\n",
        "      model = train_model(X_tr, y_tr, X_val, y_val, num_classes, f)\n",
        "      y_pred=predict_model(model, X_test, f)\n",
        "      get_score(y, y_pred, num_classes)\n",
        "\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaAsIs4p47Qo"
      },
      "source": [
        "def stacking(X_val, y_val, X_test, y_test):\n",
        "  model_0 = joblib.load('')\n",
        "  model_1 = joblib.load('')\n",
        "  model_2 = joblib.load('')\n",
        "\n",
        "  y_pred_0 = model_0.predict(X_test,num_iteration=model_0.best_iteration) #or predict_proba()\n",
        "  y_pred_1 = model_1.predict(X_test, num_iteration=model_1.best_iteration) #or predict_proba()\n",
        "\n",
        "  '''\n",
        "  #pattern1 : \n",
        "  y_pred = (y_pred_0+y_pred_1)/2\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "  #pattern2 :  you can use it if not use X_val when training model\n",
        "  stack_pred = np.column_stack((y_pred_0, y_pred_1))\n",
        "  model=model_2.fit(stack_pred, y)\n",
        "  y_pred = model.predict(X)\n",
        "  '''\n",
        "  \n",
        "  get_score(y, y_pred, num_classes)\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4Z0KeCur_XX"
      },
      "source": [
        "def main():\n",
        "    os.makedirs(LOG_DIR, exist_ok=True)\n",
        "    X_tr, y_tr, X_val, y_val, X_test, y_test, num_classes=get_data()\n",
        "    train(X_tr, y_tr, X_val, y_val, X_test, y_test, num_classes)\n",
        "    print('LOG_DIR:', LOG_DIR)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}